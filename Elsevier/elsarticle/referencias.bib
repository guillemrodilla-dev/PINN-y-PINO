@Article{app15148092,
AUTHOR = {Ren, Zhiyuan and Zhou, Shijie and Liu, Dong and Liu, Qihe},
TITLE = {Physics-Informed Neural Networks: A Review of Methodological Evolution, Theoretical Foundations, and Interdisciplinary Frontiers Toward Next-Generation Scientific Computing},
JOURNAL = {Applied Sciences},
VOLUME = {15},
YEAR = {2025},
NUMBER = {14},
ARTICLE-NUMBER = {8092},
URL = {https://www.mdpi.com/2076-3417/15/14/8092},
ISSN = {2076-3417},
ABSTRACT = {Physics-informed neural networks (PINNs) have emerged as a transformative methodology integrating deep learning with scientific computing. This review establishes a three-dimensional analytical framework to systematically decode PINNs’ development through methodological innovation, theoretical breakthroughs, and cross-disciplinary convergence. The contributions include threefold: First, identifying the co-evolutionary path of algorithmic architectures from adaptive optimization (neural tangent kernel-guided weighting achieving 230% convergence acceleration in Navier-Stokes solutions) to hybrid numerical-deep learning integration (5× speedup via domain decomposition) and second, constructing bidirectional theory-application mappings where convergence analysis (operator approximation theory) and generalization guarantees (Bayesian-physical hybrid frameworks) directly inform engineering implementations, as validated by 72% cost reduction compared to FEM in high-dimensional spaces (p<0.01,n=15 benchmarks). Third, pioneering cross-domain knowledge transfer through application-specific architectures: TFE-PINN for turbulent flows (5.12±0.87% error in NASA hypersonic tests), ReconPINN for medical imaging (▵SSIM=+0.18±0.04 on multi-institutional MRI), and SeisPINN for seismic systems (0.52±0.18 km localization accuracy). We further present a technological roadmap highlighting three critical directions for PINN 2.0: neuro-symbolic, federated physics learning, and quantum-accelerated optimization. This work provides methodological guidelines and theoretical foundations for next-generation scientific machine learning systems.},
DOI = {10.3390/app15148092}
}

@article{Luo2025,
  author  = {Luo, Kuang and Zhao, Jingshang and Wang, Yingping and Li, Jiayao and Wen, Junjie and Liang, Jiong and Soekmadji, Henry and Liao, Shaolin},
  title   = {Physics-informed neural networks for PDE problems: a comprehensive review},
  journal = {Artificial Intelligence Review},
  year    = {2025},
  volume  = {58},
  number  = {10},
  pages   = {323},
  doi     = {10.1007/s10462-025-11322-7},
  url     = {https://doi.org/10.1007/s10462-025-11322-7},
  issn    = {1573-7462},
  abstract= {As AI for Science continues to grow, Physics-informed neural networks (PINNs) have emerged as a transformative approach within the realm of scientific computing and deep learning, offering a robust and flexible framework for solving partial differential equations (PDEs) and other complex physical systems. By embedding physical laws directly into the architecture of neural networks, PINNs enable the integration of domain-specific knowledge, ensuring that the models adhere to known physics while fitting available data. In this paper, we provide a comprehensive overview of the state-of-the-art advancements and applications of PINNs across a broad spectrum of PDE problems. In particular, focus is given on the PINN architectures, data resampling methods for PINN, loss and activation functions, feature embedding methods and so on. What’s more, the potential future directions and the anticipated evolution of PINNs are also discussed. We aim to provide valuable insights into PINNs for PDE problems, with hope to encourage further exploration and research in this promising area.}
}

@misc{zhang2025physicsinformedneuralnetworksneural,
      title={Physics-Informed Neural Networks and Neural Operators for Parametric PDEs: A Human-AI Collaborative Analysis}, 
      author={Zhuo Zhang and Xiong Xiong and Sen Zhang and Yuan Zhao and Xi Yang},
      year={2025},
      eprint={2511.04576},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/2511.04576}, 

}

@article{Pino_Li,
author = {Li, Zongyi and Zheng, Hongkai and Kovachki, Nikola and Jin, David and Chen, Haoxuan and Liu, Burigede and Azizzadenesheli, Kamyar and Anandkumar, Anima},
title = {Physics-Informed Neural Operator for Learning Partial Differential Equations},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {3},
url = {https://doi.org/10.1145/3648506},
doi = {10.1145/3648506},
journal = {ACM / IMS J. Data Sci.},
month = may,
articleno = {9},
numpages = {27},
keywords = {Neural operators, physics informed learning, partial differential equations}
}
